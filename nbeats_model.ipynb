{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEQ_LEN = 30         \n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_DIM = 64\n",
        "NUM_EPOCHS = 30\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/SHEL_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "feature_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
        "values = df[feature_cols].astype(np.float32).values\n",
        "n_samples, n_features = values.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_idx = int(0.9 * n_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "values_train = values[:split_idx]\n",
        "scaler.fit(values_train)\n",
        "values_scaled = scaler.transform(values).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_sequences(values_scaled, seq_len, split_idx):\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    for t in range(seq_len, split_idx):\n",
        "        X_train.append(values_scaled[t-seq_len:t])\n",
        "        y_train.append(values_scaled[t])\n",
        "\n",
        "    n_total = values_scaled.shape[0]\n",
        "    for t in range(split_idx, n_total):\n",
        "        if t - seq_len < 0:\n",
        "            continue\n",
        "        X_test.append(values_scaled[t-seq_len:t])\n",
        "        y_test.append(values_scaled[t])\n",
        "\n",
        "    X_train = np.stack(X_train)  \n",
        "    y_train = np.stack(y_train) \n",
        "    X_test = np.stack(X_test)    \n",
        "    y_test = np.stack(y_test)    \n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train, y_train, X_test, y_test = make_sequences(values_scaled, SEQ_LEN, split_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Train sequences:\", X_train.shape, \"Test sequences:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X)  \n",
        "        self.y = torch.from_numpy(y) \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = TimeSeriesDataset(X_train, y_train)\n",
        "test_ds = TimeSeriesDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NBeatsBlock(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        flattened_size = SEQ_LEN * input_dim\n",
        "        self.fc1 = nn.Linear(flattened_size, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.backcast = nn.Linear(hidden_dim, flattened_size)\n",
        "        self.forecast = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x_flat):\n",
        "        x = self.relu(self.fc1(x_flat))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.relu(self.fc4(x))\n",
        "        backcast = self.backcast(x)  # [B, T*D]\n",
        "        forecast = self.forecast(x)  # [B, D]\n",
        "        return backcast, forecast\n",
        "\n",
        "\n",
        "class NBeatsForecaster(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_stacks=2, num_blocks=1):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList()\n",
        "        for _ in range(num_stacks):\n",
        "            for _ in range(num_blocks):\n",
        "                self.blocks.append(NBeatsBlock(input_dim, hidden_dim, output_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        x_flat = x.view(B, -1) \n",
        "        forecast_sum = 0\n",
        "        for block in self.blocks:\n",
        "            backcast, forecast = block(x_flat)\n",
        "            forecast_sum = forecast_sum + forecast\n",
        "            x_flat = x_flat - backcast  # residual \n",
        "        return forecast_sum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_model(model_name=\"N-BEATS\"):\n",
        "    return NBeatsForecaster(n_features, HIDDEN_DIM, n_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model_name=\"N-BEATS\"):\n",
        "    model = make_model(model_name).to(DEVICE)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        train_loss /= len(train_ds)\n",
        "        if epoch % 5 == 0 or epoch == 1:\n",
        "            print(f\"[{model_name}] Epoch {epoch}/{NUM_EPOCHS}, \"\n",
        "                  f\"Train MSE (scaled): {train_loss:.4f}\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(y_true_scaled, y_pred_scaled, X_test_scaled_last):\n",
        "    \n",
        "    mse_scaled = np.mean((y_pred_scaled - y_true_scaled) ** 2)\n",
        "    rmse_scaled = np.sqrt(mse_scaled)\n",
        "\n",
        "    y_true = scaler.inverse_transform(y_true_scaled)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "    eps = 1e-6\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100.0\n",
        "\n",
        "    last = X_test_scaled_last\n",
        "    actual_change = np.sign(y_true_scaled - last)\n",
        "    pred_change = np.sign(y_pred_scaled - last)\n",
        "    correct_dir = (actual_change == pred_change).astype(np.float32)\n",
        "    mda = correct_dir.mean()\n",
        "\n",
        "    r2 = r2_score(\n",
        "        y_true_scaled.reshape(-1),\n",
        "        y_pred_scaled.reshape(-1)\n",
        "    )\n",
        "\n",
        "    bias_per_feature = np.mean(y_pred - y_true, axis=0)  # [D]\n",
        "    bias_overall = bias_per_feature.mean()\n",
        "    # classify over / under / none\n",
        "    avg_abs_level = np.mean(np.abs(y_true))\n",
        "    threshold = 0.01 * avg_abs_level  # 1% of average magnitude\n",
        "    if abs(bias_overall) < threshold:\n",
        "        bias_flag = \"None / minimal\"\n",
        "    elif bias_overall > 0:\n",
        "        bias_flag = \"Over-forecast (too high)\"\n",
        "    else:\n",
        "        bias_flag = \"Under-forecast (too low)\"\n",
        "\n",
        "    metrics = {\n",
        "        \"Scaled_RMSE\": float(rmse_scaled),\n",
        "        \"MAPE_percent\": float(mape),\n",
        "        \"MDA\": float(mda),\n",
        "        \"R2\": float(r2),\n",
        "        \"Bias_overall\": float(bias_overall),\n",
        "        \"Bias_flag\": bias_flag,\n",
        "        \"Bias_per_feature\": dict(zip(feature_cols, bias_per_feature))\n",
        "    }\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**N-BEATS**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"Open Source Model #4\"\n",
        "model = train_model(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "all_preds_scaled = []\n",
        "all_true_scaled = []\n",
        "all_last_inputs_scaled = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "        preds = model(xb)\n",
        "\n",
        "        all_preds_scaled.append(preds.cpu().numpy())\n",
        "        all_true_scaled.append(yb.cpu().numpy())\n",
        "        all_last_inputs_scaled.append(xb[:, -1, :].cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_scaled = np.concatenate(all_preds_scaled, axis=0)   # [N_test, D]\n",
        "y_true_scaled = np.concatenate(all_true_scaled, axis=0)    # [N_test, D]\n",
        "X_last_scaled = np.concatenate(all_last_inputs_scaled, axis=0)  # [N_test, D]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = compute_metrics(y_true_scaled, y_pred_scaled, X_last_scaled)\n",
        "print(\"\\n=== Metrics for\", model_name, \"===\")\n",
        "for k, v in metrics.items():\n",
        "    if isinstance(v, dict):\n",
        "        print(k, \":\")\n",
        "        for kk, vv in v.items():\n",
        "            print(f\"  {kk}: {vv:.4f}\")\n",
        "    else:\n",
        "        print(k, \":\", v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row_for_sheet = {\n",
        "    \"Model\": model_name,\n",
        "    \"Scaled RMSE\": metrics[\"Scaled_RMSE\"],\n",
        "    \"MAPE\": metrics[\"MAPE_percent\"],\n",
        "    \"Mean Directional Accuracy (MDA)\": metrics[\"MDA\"],\n",
        "    \"R^2\": metrics[\"R2\"],\n",
        "    \"Forecast Bias?\": metrics[\"Bias_flag\"],\n",
        "}\n",
        "print(\"\\nRow for spreadsheet:\", row_for_sheet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = scaler.inverse_transform(y_true_scaled)\n",
        "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "\n",
        "n_test = y_true.shape[0]\n",
        "t_axis = np.arange(n_test)\n",
        "\n",
        "fig, axes = plt.subplots(n_features, 1,\n",
        "                         figsize=(12, 3 * n_features),\n",
        "                         sharex=True)\n",
        "\n",
        "if n_features == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for d, col in enumerate(feature_cols):\n",
        "    ax = axes[d]\n",
        "    ax.plot(t_axis, y_true[:, d], label=f\"True {col}\")\n",
        "    ax.plot(t_axis, y_pred[:, d], label=f\"Pred {col}\")\n",
        "    ax.set_ylabel(col)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    if d == 0:\n",
        "        ax.legend(loc=\"upper right\")\n",
        "\n",
        "axes[-1].set_xlabel(\"Test window index (time)\")\n",
        "plt.suptitle(f\"{model_name}: True vs Pred on Holdout (last 10%)\")\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
