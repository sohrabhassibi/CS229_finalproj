{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Try to import Moirai\n",
        "try:\n",
        "    from uni2ts.model.moirai import MoiraiForecast\n",
        "    from uni2ts.model.moirai.module import MoiraiModule\n",
        "    MOIRAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: uni2ts not available. Moirai model cannot be used.\")\n",
        "    MOIRAI_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEQ_LEN = 30          # lookback window length\n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_DIM = 64\n",
        "NUM_EPOCHS = 30\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/SHEL_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "feature_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
        "values = df[feature_cols].astype(np.float32).values\n",
        "n_samples, n_features = values.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_idx = int(0.9 * n_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "values_train = values[:split_idx]\n",
        "scaler.fit(values_train)\n",
        "values_scaled = scaler.transform(values).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_sequences(values_scaled, seq_len, split_idx):\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    # training sequences: target index t in [seq_len, split_idx-1]\n",
        "    for t in range(seq_len, split_idx):\n",
        "        X_train.append(values_scaled[t-seq_len:t])\n",
        "        y_train.append(values_scaled[t])\n",
        "\n",
        "    # test sequences: target index t in [split_idx, n_samples-1]\n",
        "    n_total = values_scaled.shape[0]\n",
        "    for t in range(split_idx, n_total):\n",
        "        if t - seq_len < 0:\n",
        "            continue\n",
        "        X_test.append(values_scaled[t-seq_len:t])\n",
        "        y_test.append(values_scaled[t])\n",
        "\n",
        "    X_train = np.stack(X_train)  # [N_train, T, D]\n",
        "    y_train = np.stack(y_train)  # [N_train, D]\n",
        "    X_test = np.stack(X_test)    # [N_test, T, D]\n",
        "    y_test = np.stack(y_test)    # [N_test, D]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train, y_train, X_test, y_test = make_sequences(values_scaled, SEQ_LEN, split_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Train sequences:\", X_train.shape, \"Test sequences:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(y_true_scaled, y_pred_scaled, X_test_scaled_last):\n",
        "    \"\"\"\n",
        "    y_true_scaled: [N, D]\n",
        "    y_pred_scaled: [N, D]\n",
        "    X_test_scaled_last: [N, D]  (last input of each window, scaled)\n",
        "    \"\"\"\n",
        "    # Scaled RMSE\n",
        "    mse_scaled = np.mean((y_pred_scaled - y_true_scaled) ** 2)\n",
        "    rmse_scaled = np.sqrt(mse_scaled)\n",
        "\n",
        "    # MAPE (on original scale)\n",
        "    y_true = scaler.inverse_transform(y_true_scaled)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "    eps = 1e-6\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100.0\n",
        "\n",
        "    # Mean Directional Accuracy (direction of change from last input to target)\n",
        "    # use scaled values (sign preserved)\n",
        "    last = X_test_scaled_last\n",
        "    actual_change = np.sign(y_true_scaled - last)\n",
        "    pred_change = np.sign(y_pred_scaled - last)\n",
        "    correct_dir = (actual_change == pred_change).astype(np.float32)\n",
        "    mda = correct_dir.mean()\n",
        "\n",
        "    # R^2 (on scaled)\n",
        "    r2 = r2_score(\n",
        "        y_true_scaled.reshape(-1),\n",
        "        y_pred_scaled.reshape(-1)\n",
        "    )\n",
        "\n",
        "    # Forecast bias (on original)\n",
        "    bias_per_feature = np.mean(y_pred - y_true, axis=0)  # [D]\n",
        "    bias_overall = bias_per_feature.mean()\n",
        "    # classify: over / under / none\n",
        "    avg_abs_level = np.mean(np.abs(y_true))\n",
        "    threshold = 0.01 * avg_abs_level  # 1% of average magnitude\n",
        "    if abs(bias_overall) < threshold:\n",
        "        bias_flag = \"None / minimal\"\n",
        "    elif bias_overall > 0:\n",
        "        bias_flag = \"Over-forecast (too high)\"\n",
        "    else:\n",
        "        bias_flag = \"Under-forecast (too low)\"\n",
        "\n",
        "    metrics = {\n",
        "        \"Scaled_RMSE\": float(rmse_scaled),\n",
        "        \"MAPE_percent\": float(mape),\n",
        "        \"MDA\": float(mda),\n",
        "        \"R2\": float(r2),\n",
        "        \"Bias_overall\": float(bias_overall),\n",
        "        \"Bias_flag\": bias_flag,\n",
        "        \"Bias_per_feature\": dict(zip(feature_cols, bias_per_feature))\n",
        "    }\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row_for_sheet = {\n",
        "    \"Model\": model_name,\n",
        "    \"Scaled RMSE\": metrics[\"Scaled_RMSE\"],\n",
        "    \"MAPE\": metrics[\"MAPE_percent\"],\n",
        "    \"Mean Directional Accuracy (MDA)\": metrics[\"MDA\"],\n",
        "    \"R^2\": metrics[\"R2\"],\n",
        "    \"Forecast Bias?\": metrics[\"Bias_flag\"],\n",
        "}\n",
        "print(\"\\nRow for spreadsheet:\", row_for_sheet)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**SALESFORCE MOIRAI MODEL**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"Salesforce Morai Model\"\n",
        "\n",
        "if not MOIRAI_AVAILABLE:\n",
        "    print(\"Moirai model not available. Please install uni2ts: pip install uni2ts\")\n",
        "    print(\"For now, using a placeholder that will show the expected format.\")\n",
        "    \n",
        "    # Placeholder predictions (mean of last timestep)\n",
        "    all_preds_scaled = []\n",
        "    all_true_scaled = []\n",
        "    all_last_inputs_scaled = []\n",
        "    \n",
        "    for i in range(len(X_test)):\n",
        "        all_preds_scaled.append(X_test[i, -1, :])  # Use last timestep as prediction\n",
        "        all_true_scaled.append(y_test[i])\n",
        "        all_last_inputs_scaled.append(X_test[i, -1, :])\n",
        "    \n",
        "    y_pred_scaled = np.array(all_preds_scaled)\n",
        "    y_true_scaled = np.array(all_true_scaled)\n",
        "    X_last_scaled = np.array(all_last_inputs_scaled)\n",
        "    \n",
        "else:\n",
        "    # Use Moirai model\n",
        "    try:\n",
        "        # Moirai works with univariate series, so we'll process each feature separately\n",
        "        # and combine predictions\n",
        "        all_preds_scaled = []\n",
        "        all_true_scaled = []\n",
        "        all_last_inputs_scaled = []\n",
        "        \n",
        "        # Initialize Moirai model (using small version for efficiency)\n",
        "        moirai_model = MoiraiForecast(\n",
        "            module=MoiraiModule.from_pretrained(\"Salesforce/moirai-1.0-R-small\"),\n",
        "            prediction_length=1,\n",
        "            context_length=SEQ_LEN,\n",
        "            target_dim=1,\n",
        "            feat_dynamic_real_dim=0,\n",
        "            past_feat_dynamic_real_dim=0,\n",
        "        )\n",
        "        \n",
        "        predictor = moirai_model.create_predictor(batch_size=BATCH_SIZE)\n",
        "        \n",
        "        # Process each test sample\n",
        "        for i in range(len(X_test)):\n",
        "            # Moirai expects format: [T] for univariate\n",
        "            # We'll average across features or use first feature as proxy\n",
        "            # For multivariate, we process each feature separately\n",
        "            preds_per_feature = []\n",
        "            \n",
        "            for feat_idx in range(n_features):\n",
        "                # Extract univariate series for this feature\n",
        "                univariate_series = X_test[i, :, feat_idx]  # [T]\n",
        "                \n",
        "                # Convert to Moirai format (list of dicts)\n",
        "                from gluonts.dataset.common import ListDataset\n",
        "                test_data = ListDataset(\n",
        "                    [{\"target\": univariate_series, \"start\": pd.Timestamp(\"2020-01-01\")}],\n",
        "                    freq=\"D\"\n",
        "                )\n",
        "                \n",
        "                # Get prediction\n",
        "                forecasts = list(predictor.predict(test_data))\n",
        "                if len(forecasts) > 0:\n",
        "                    pred_value = forecasts[0].mean[0]  # Get mean prediction\n",
        "                else:\n",
        "                    pred_value = univariate_series[-1]  # Fallback to last value\n",
        "                \n",
        "                preds_per_feature.append(pred_value)\n",
        "            \n",
        "            all_preds_scaled.append(np.array(preds_per_feature))\n",
        "            all_true_scaled.append(y_test[i])\n",
        "            all_last_inputs_scaled.append(X_test[i, -1, :])\n",
        "        \n",
        "        y_pred_scaled = np.array(all_preds_scaled)\n",
        "        y_true_scaled = np.array(all_true_scaled)\n",
        "        X_last_scaled = np.array(all_last_inputs_scaled)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error using Moirai model: {e}\")\n",
        "        print(\"Falling back to simple baseline (last timestep)\")\n",
        "        \n",
        "        # Fallback: use last timestep as prediction\n",
        "        all_preds_scaled = []\n",
        "        all_true_scaled = []\n",
        "        all_last_inputs_scaled = []\n",
        "        \n",
        "        for i in range(len(X_test)):\n",
        "            all_preds_scaled.append(X_test[i, -1, :])\n",
        "            all_true_scaled.append(y_test[i])\n",
        "            all_last_inputs_scaled.append(X_test[i, -1, :])\n",
        "        \n",
        "        y_pred_scaled = np.array(all_preds_scaled)\n",
        "        y_true_scaled = np.array(all_true_scaled)\n",
        "        X_last_scaled = np.array(all_last_inputs_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = compute_metrics(y_true_scaled, y_pred_scaled, X_last_scaled)\n",
        "print(\"\\n=== Metrics for\", model_name, \"===\")\n",
        "for k, v in metrics.items():\n",
        "    if isinstance(v, dict):\n",
        "        print(k, \":\")\n",
        "        for kk, vv in v.items():\n",
        "            print(f\"  {kk}: {vv:.4f}\")\n",
        "    else:\n",
        "        print(k, \":\", v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row_for_sheet = {\n",
        "    \"Model\": model_name,\n",
        "    \"Scaled RMSE\": metrics[\"Scaled_RMSE\"],\n",
        "    \"MAPE\": metrics[\"MAPE_percent\"],\n",
        "    \"Mean Directional Accuracy (MDA)\": metrics[\"MDA\"],\n",
        "    \"R^2\": metrics[\"R2\"],\n",
        "    \"Forecast Bias?\": metrics[\"Bias_flag\"],\n",
        "}\n",
        "print(\"\\nRow for spreadsheet:\", row_for_sheet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = scaler.inverse_transform(y_true_scaled)\n",
        "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "\n",
        "n_test = y_true.shape[0]\n",
        "t_axis = np.arange(n_test)\n",
        "\n",
        "fig, axes = plt.subplots(n_features, 1,\n",
        "                         figsize=(12, 3 * n_features),\n",
        "                         sharex=True)\n",
        "\n",
        "if n_features == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for d, col in enumerate(feature_cols):\n",
        "    ax = axes[d]\n",
        "    ax.plot(t_axis, y_true[:, d], label=f\"True {col}\")\n",
        "    ax.plot(t_axis, y_pred[:, d], label=f\"Pred {col}\")\n",
        "    ax.set_ylabel(col)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    if d == 0:\n",
        "        ax.legend(loc=\"upper right\")\n",
        "\n",
        "axes[-1].set_xlabel(\"Test window index (time)\")\n",
        "plt.suptitle(f\"{model_name}: True vs Pred on Holdout (last 10%)\")\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
