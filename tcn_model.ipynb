{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEQ_LEN = 30\n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_DIM = 64\n",
        "NUM_EPOCHS = 30\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/SHEL_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "feature_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
        "values = df[feature_cols].astype(np.float32).values\n",
        "n_samples, n_features = values.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_idx = int(0.9 * n_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "values_train = values[:split_idx]\n",
        "scaler.fit(values_train)\n",
        "values_scaled = scaler.transform(values).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_sequences(values_scaled, seq_len, split_idx):\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    for t in range(seq_len, split_idx):\n",
        "        X_train.append(values_scaled[t-seq_len:t])\n",
        "        y_train.append(values_scaled[t])\n",
        "\n",
        "    n_total = values_scaled.shape[0]\n",
        "    for t in range(split_idx, n_total):\n",
        "        if t - seq_len < 0:\n",
        "            continue\n",
        "        X_test.append(values_scaled[t-seq_len:t])\n",
        "        y_test.append(values_scaled[t])\n",
        "\n",
        "    X_train = np.stack(X_train)\n",
        "    y_train = np.stack(y_train)\n",
        "    X_test = np.stack(X_test)\n",
        "    y_test = np.stack(y_test)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train, y_train, X_test, y_test = make_sequences(values_scaled, SEQ_LEN, split_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Train sequences:\", X_train.shape, \"Test sequences:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = TimeSeriesDataset(X_train, y_train)\n",
        "test_ds = TimeSeriesDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super().__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, dropout=0.2):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) * dilation\n",
        "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TCNForecaster(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_levels=3, kernel_size=3):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_channels = [hidden_dim] * num_levels\n",
        "        num_channels[0] = hidden_dim\n",
        "\n",
        "        for i in range(len(num_channels)):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = input_dim if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size,\n",
        "                                     stride=1, dilation=dilation_size)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        y = self.network(x)\n",
        "        y = y[:, :, -1]\n",
        "        pred = self.fc(y)\n",
        "        return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_model(model_name=\"TCN\"):\n",
        "    return TCNForecaster(n_features, HIDDEN_DIM, n_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model_name=\"TCN\"):\n",
        "    model = make_model(model_name).to(DEVICE)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        train_loss /= len(train_ds)\n",
        "        if epoch % 5 == 0 or epoch == 1:\n",
        "            print(f\"[{model_name}] Epoch {epoch}/{NUM_EPOCHS}, \"\n",
        "                  f\"Train MSE (scaled): {train_loss:.4f}\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(y_true_scaled, y_pred_scaled, X_test_scaled_last):\n",
        "   \n",
        "    mse_scaled = np.mean((y_pred_scaled - y_true_scaled) ** 2)\n",
        "    rmse_scaled = np.sqrt(mse_scaled)\n",
        "\n",
        "    y_true = scaler.inverse_transform(y_true_scaled)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "    eps = 1e-6\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100.0\n",
        "\n",
        "    last = X_test_scaled_last\n",
        "    actual_change = np.sign(y_true_scaled - last)\n",
        "    pred_change = np.sign(y_pred_scaled - last)\n",
        "    correct_dir = (actual_change == pred_change).astype(np.float32)\n",
        "    mda = correct_dir.mean()\n",
        "\n",
        "    r2 = r2_score(\n",
        "        y_true_scaled.reshape(-1),\n",
        "        y_pred_scaled.reshape(-1)\n",
        "    )\n",
        "\n",
        "    bias_per_feature = np.mean(y_pred - y_true, axis=0)  # [D]\n",
        "    bias_overall = bias_per_feature.mean()\n",
        "    avg_abs_level = np.mean(np.abs(y_true))\n",
        "    threshold = 0.01 * avg_abs_level  # 1% of average magnitude\n",
        "    if abs(bias_overall) < threshold:\n",
        "        bias_flag = \"None / minimal\"\n",
        "    elif bias_overall > 0:\n",
        "        bias_flag = \"Over-forecast (too high)\"\n",
        "    else:\n",
        "        bias_flag = \"Under-forecast (too low)\"\n",
        "\n",
        "    metrics = {\n",
        "        \"Scaled_RMSE\": float(rmse_scaled),\n",
        "        \"MAPE_percent\": float(mape),\n",
        "        \"MDA\": float(mda),\n",
        "        \"R2\": float(r2),\n",
        "        \"Bias_overall\": float(bias_overall),\n",
        "        \"Bias_flag\": bias_flag,\n",
        "        \"Bias_per_feature\": dict(zip(feature_cols, bias_per_feature))\n",
        "    }\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TCN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"Open Source Model #5\"\n",
        "model = train_model(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "all_preds_scaled = []\n",
        "all_true_scaled = []\n",
        "all_last_inputs_scaled = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "        preds = model(xb)\n",
        "\n",
        "        all_preds_scaled.append(preds.cpu().numpy())\n",
        "        all_true_scaled.append(yb.cpu().numpy())\n",
        "        all_last_inputs_scaled.append(xb[:, -1, :].cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_scaled = np.concatenate(all_preds_scaled, axis=0)\n",
        "y_true_scaled = np.concatenate(all_true_scaled, axis=0)\n",
        "X_last_scaled = np.concatenate(all_last_inputs_scaled, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = compute_metrics(y_true_scaled, y_pred_scaled, X_last_scaled)\n",
        "print(\"\\n=== Metrics for\", model_name, \"===\")\n",
        "for k, v in metrics.items():\n",
        "    if isinstance(v, dict):\n",
        "        print(k, \":\")\n",
        "        for kk, vv in v.items():\n",
        "            print(f\"  {kk}: {vv:.4f}\")\n",
        "    else:\n",
        "        print(k, \":\", v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row_for_sheet = {\n",
        "    \"Model\": model_name,\n",
        "    \"Scaled RMSE\": metrics[\"Scaled_RMSE\"],\n",
        "    \"MAPE\": metrics[\"MAPE_percent\"],\n",
        "    \"Mean Directional Accuracy (MDA)\": metrics[\"MDA\"],\n",
        "    \"R^2\": metrics[\"R2\"],\n",
        "    \"Forecast Bias?\": metrics[\"Bias_flag\"],\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = scaler.inverse_transform(y_true_scaled)\n",
        "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "\n",
        "n_test = y_true.shape[0]\n",
        "t_axis = np.arange(n_test)\n",
        "\n",
        "fig, axes = plt.subplots(n_features, 1,\n",
        "                         figsize=(12, 3 * n_features),\n",
        "                         sharex=True)\n",
        "\n",
        "if n_features == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for d, col in enumerate(feature_cols):\n",
        "    ax = axes[d]\n",
        "    ax.plot(t_axis, y_true[:, d], label=f\"True {col}\")\n",
        "    ax.plot(t_axis, y_pred[:, d], label=f\"Pred {col}\")\n",
        "    ax.set_ylabel(col)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    if d == 0:\n",
        "        ax.legend(loc=\"upper right\")\n",
        "\n",
        "axes[-1].set_xlabel(\"Test window index (time)\")\n",
        "plt.suptitle(f\"{model_name}: True vs pred on Holdout (last 10%)\")\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
